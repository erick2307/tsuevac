{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tsuevac/lib/python3.9/site-packages/geopandas/_compat.py:111: UserWarning: The Shapely GEOS version (3.10.2-CAPI-1.16.0) is incompatible with the GEOS version PyGEOS was compiled with (3.10.0-CAPI-1.16.0). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import shapely as shp\n",
    "from lib import getPopulation as gp\n",
    "from lib import setActionsAndTransitions as actrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolders():\n",
    "    tempfolder = Path(\"./tmp\")\n",
    "    if not Path.exists(tempfolder):\n",
    "        Path.mkdir(tempfolder)\n",
    "    datafolder = Path(\"./data\")\n",
    "    if not Path.exists(datafolder):\n",
    "        Path.mkdir(datafolder)\n",
    "\n",
    "\n",
    "def get_area_from_geojson(aos_file):\n",
    "    gdf = gpd.read_file(aos_file)\n",
    "    bbox = gdf.total_bounds\n",
    "    area = {\"north\": bbox[3], \"south\": bbox[1], \"east\": bbox[2], \"west\": bbox[0]}\n",
    "    return area\n",
    "\n",
    "\n",
    "def createBoundingBox(\n",
    "    area={\"north\": 33.58, \"south\": 33.53, \"east\": 133.58, \"west\": 133.52}\n",
    "):\n",
    "    # create a Bounding Box\n",
    "    # returns a shapely geometry\n",
    "    bbox = shp.geometry.box(area[\"west\"], area[\"south\"], area[\"east\"], area[\"north\"])\n",
    "    return bbox\n",
    "\n",
    "\n",
    "def createGraph(\n",
    "    area={\"north\": 33.58, \"south\": 33.53, \"east\": 133.58, \"west\": 133.52},\n",
    "    crs=\"EPSG:6690\",\n",
    "    ntype=\"drive\",\n",
    "    simplify=False,\n",
    "):\n",
    "    # NEW AREA (Aug, 2021)\n",
    "    maprange = area  # Degree 1.0 = 111km. 2.22km x 4.44km square.\n",
    "    # Obtain the roadmap data from OpenStreetMap by using OSMNX\n",
    "    G = ox.graph_from_bbox(\n",
    "        maprange[\"north\"],\n",
    "        maprange[\"south\"],\n",
    "        maprange[\"east\"],\n",
    "        maprange[\"west\"],\n",
    "        network_type=ntype,\n",
    "        simplify=simplify,\n",
    "    )\n",
    "    G_projected = ox.project_graph(G, to_crs=crs)\n",
    "    if simplify:\n",
    "        # Simplify topology\n",
    "        G_out = ox.simplification.consolidate_intersections(\n",
    "            G_projected,\n",
    "            tolerance=10,\n",
    "            rebuild_graph=True,\n",
    "            dead_ends=False,\n",
    "            reconnect_edges=True,\n",
    "        )\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        The graph was saved as 'graph.gpkg' with projection {crs}.\n",
    "        This is a SIMPLIFIED {ntype} type OSM network.\n",
    "        \"\"\"\n",
    "        )\n",
    "    else:\n",
    "        G_out = G_projected\n",
    "        print(\n",
    "            f\"\"\"\n",
    "        The graph was saved as 'graph.gpkg' with projection {crs}.\n",
    "        This is an {ntype} type OSM network.\n",
    "        \"\"\"\n",
    "        )\n",
    "    # save the OSM data as Geopackage\n",
    "    ox.io.save_graph_geopackage(G_out, filepath=\"./tmp/graph.gpkg\")\n",
    "    # # Draw a map\n",
    "    # if plot:\n",
    "    #     ox.plot_graph(G_out, bgcolor=\"white\", node_color=\"red\", edge_color=\"black\")\n",
    "    # # Create edges file\n",
    "    # edges = gpd.read_file(\"./tmp/graph.gpkg\", layer=\"edges\")\n",
    "    # edges.to_file(\"./tmp/edges.shp\")\n",
    "    nnodes = G.number_of_nodes()\n",
    "    nedges = G.number_of_edges()\n",
    "    print(f\"{nnodes} nodes and {nedges} edges in graph.\")\n",
    "    return G_out\n",
    "\n",
    "def createLinksAndNodes(G,shelters, plot=True):\n",
    "    # Get nodes and edge from graph\n",
    "    n, e = ox.graph_to_gdfs(G)\n",
    "    # Create nodes db\n",
    "    nodesdb = n[['x','y']].copy()\n",
    "    nodesdb['evacuation'] = pd.Series([ 0 for _ in range(nodesdb.shape[0])])\n",
    "    nodesdb['reward'] = pd.Series([ 1 for _ in range(nodesdb.shape[0])])\n",
    "    nodesdb['number'] = pd.Series([ i for i in range(nodesdb.shape[0])])\n",
    "    nodesdb = nodesdb.rename(columns={'x' : 'coord_x', 'y': 'coord_y'})\n",
    "    nodesdb0 = nodesdb[['number','coord_x','coord_y','evacuation','reward']]\n",
    "    nodesdb0.to_csv('./tmp/nodesdb0.csv',index=False)\n",
    "    # Create linksdb\n",
    "    linksdb = np.zeros((e.shape[0],5),dtype=np.int64)\n",
    "    for i,j in enumerate(e.iterrows()):\n",
    "        u = j[0][0]\n",
    "        v = j[0][1]\n",
    "        linksdb[i,:] = [i,u,v,np.int64(j[1][3]),3]\n",
    "    linksdb0 = pd.DataFrame(linksdb, columns=['number','node1','node2','length','width'])\n",
    "    linksdb0.to_csv('./tmp/linksdb0.csv',index=False)\n",
    "    # Fix the nodesdb\n",
    "    if shelters.shape[0] > 0:\n",
    "        print('Warning!: No shelters!')\n",
    "        fixLinksDBAndNodesDB(shelters)\n",
    "    else:\n",
    "        np.savetxt(\n",
    "        \"./data/nodesdb.csv\",\n",
    "        nodesdb0,\n",
    "        delimiter=\",\",\n",
    "        header=\"number,coord_x,coord_y,evacuation,reward\",\n",
    "        fmt=\"%d,%.6f,%.6f,%d,%d\",\n",
    "    )\n",
    "    np.savetxt(\n",
    "        \"./data/linksdb.csv\",\n",
    "        linksdb0,\n",
    "        delimiter=\",\",\n",
    "        header=\"number,node1,node2,length,width\",\n",
    "        fmt=\"%d,%d,%d,%d,%d\",\n",
    "    )\n",
    "    if plot:\n",
    "        plotNetwork()\n",
    "    return\n",
    "\n",
    "def plotNetwork():\n",
    "    noDB = np.loadtxt(\"./data/nodesdb.csv\", delimiter=\",\",skiprows=1)\n",
    "    edDB = np.loadtxt(\"./data/linksdb.csv\", delimiter=\",\",skiprows=1)\n",
    "    print(noDB.shape, edDB.shape)\n",
    "    plt.figure(num=1, figsize=(10,10))\n",
    "    for i in range(edDB.shape[0]):\n",
    "        indS, indT= int(edDB[i,1]), int(edDB[i,2])\n",
    "        # print(\"here\",indS, indT)\n",
    "        plt.plot([ noDB[indS,1], noDB[indT,1] ],[ noDB[indS,2],noDB[indT,2] ], c=\"r\", lw=1)\n",
    "    plt.scatter(noDB[:,1], noDB[:,2], s= 5)\n",
    "    for i in range(noDB.shape[0]):\n",
    "        plt.annotate(str(noDB[i,0].astype(np.int64)),[noDB[i,1],noDB[i,2]])\n",
    "    plt.axis('equal')\n",
    "    plt.savefig('./data/network.png')\n",
    "    return\n",
    "    \n",
    "def getPrefShelters(pref_code=39, crs=\"EPSG:6690\", filter=True):\n",
    "    rootfolder = \"/Volumes/Pegasus32/data\"\n",
    "    datafolder = \"PAREA_Hazard_2018/data/世界測地系\"\n",
    "    areafile = f\"{pref_code:02d}/PHRP{pref_code:02d}18.shp\"\n",
    "    path = os.path.join(rootfolder, datafolder, areafile)\n",
    "    shelters_gc = gpd.read_file(path, encoding=\"shift_jis\")\n",
    "    shelters = shelters_gc.to_crs(crs)\n",
    "    if filter:\n",
    "        shelters = shelters[shelters[\"TUNAMI\"] == 1]\n",
    "    return shelters\n",
    "\n",
    "\n",
    "def getAreaShelters(\n",
    "    area={\"north\": 33.58, \"south\": 33.53, \"east\": 133.58, \"west\": 133.52},\n",
    "    pref_code=39,\n",
    "    crs=\"EPSG:6690\",\n",
    "):\n",
    "    bbox = createBoundingBox(area)\n",
    "    bbox_gdf = gpd.GeoSeries(bbox)\n",
    "    bbox_gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    bbox_gdf = bbox_gdf.to_crs(crs)\n",
    "    poly = shp.geometry.shape(bbox_gdf[0])\n",
    "    shelters = getPrefShelters(pref_code, crs)\n",
    "    gs = gpd.GeoSeries(shelters.geometry)\n",
    "    sh_in_area = shelters[gs.within(poly)]\n",
    "    return sh_in_area\n",
    "\n",
    "\n",
    "def getPrefEvacBldgs(crs=\"EPSG:4326\"):\n",
    "    rootfolder = \"/Volumes/Pegasus32/kochi/evacuation\"\n",
    "    filename = \"Kochi_EvacBldg_20211220.csv\"\n",
    "    path = Path(rootfolder, filename)\n",
    "    bldgs_pd = pd.read_csv(path)\n",
    "    bldgs = gpd.GeoDataFrame(\n",
    "        bldgs_pd, geometry=gpd.points_from_xy(bldgs_pd[\"lon\"], bldgs_pd[\"lat\"])\n",
    "    )\n",
    "    bldgs.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    bldgs.to_crs(crs)\n",
    "    return bldgs\n",
    "\n",
    "\n",
    "def getAreaEvacBldgs(\n",
    "    area={\"north\": 33.58, \"south\": 33.53, \"east\": 133.58, \"west\": 133.52},\n",
    "    crs=\"EPSG:6690\",\n",
    "):\n",
    "    bbox = createBoundingBox(area)\n",
    "    bbox_gdf = gpd.GeoSeries(bbox)\n",
    "    bbox_gdf.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    bbox_gdf = bbox_gdf.to_crs(crs)\n",
    "    poly = shp.geometry.shape(bbox_gdf[0])\n",
    "    bldgs = getPrefEvacBldgs(crs)\n",
    "    gs = gpd.GeoSeries(bldgs.geometry)\n",
    "    bldgs_in_area = bldgs[gs.within(poly)]\n",
    "    return bldgs_in_area\n",
    "\n",
    "\n",
    "def pointsWithinPolygon(poly):\n",
    "    # Get the nodes within a polygon\n",
    "    df = pd.read_csv(\"./data/nodesdb.csv\")\n",
    "    nodes = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.coord_x, df.coord_y))\n",
    "    gs = gpd.GeoSeries(nodes.geometry)\n",
    "    ninarea = nodes[gs.within(poly)]\n",
    "    return ninarea\n",
    "\n",
    "\n",
    "def fixLinksDBAndNodesDB(shelters):\n",
    "    # fixes the nodesdb to add shelters as nodes\n",
    "    # requires 'shelters' geodataframe\n",
    "    # the 'nodesdb.csv' was created with 'createLinksAndNodes.py'\n",
    "    nodesnp = np.loadtxt(\"./tmp/nodesdb0.csv\", delimiter=\",\",skiprows=1)\n",
    "    linksdb = np.loadtxt(\"./tmp/linksdb0.csv\", delimiter=\",\",skiprows=1)\n",
    "    # create a numpy array for nodesdb\n",
    "    nodesdb = np.zeros((nodesnp.shape[0], nodesnp.shape[1] + 2))\n",
    "    nodesdb[:, :3] = nodesnp[:, :3]\n",
    "    # create a pandas then numpy for shelter coords\n",
    "    sheltersdb = pd.DataFrame()\n",
    "    for i, g in zip(shelters.index, shelters[\"geometry\"]):\n",
    "        x, y = g.coords.xy\n",
    "        sheltersdb.loc[i, \"x\"], sheltersdb.loc[i, \"y\"] = x[0], y[0]\n",
    "    sheltersdb = sheltersdb.to_numpy()\n",
    "    for i in range(sheltersdb.shape[0]):\n",
    "        x0, y0 = sheltersdb[i, :]\n",
    "        dist = ((nodesnp[:, 1] - x0) ** 2 + (nodesnp[:, 2] - y0) ** 2) ** 0.5\n",
    "        indx = np.argmin(dist)\n",
    "        nodesdb[indx, 3] = 1\n",
    "    nodesdb[:, 4] += 1\n",
    "    # correcting links length = 0 to = 2\n",
    "    linksdb[:, 3][np.where(linksdb[:, 3] == 0)] = 2\n",
    "    np.savetxt(\n",
    "        \"./data/nodesdb.csv\",\n",
    "        nodesdb,\n",
    "        delimiter=\",\",\n",
    "        header=\"number,coord_x,coord_y,evacuation,reward\",\n",
    "        fmt=\"%d,%.6f,%.6f,%d,%d\",\n",
    "    )\n",
    "    np.savetxt(\n",
    "        \"./data/linksdb.csv\",\n",
    "        linksdb,\n",
    "        delimiter=\",\",\n",
    "        header=\"number,node1,node2,length,width\",\n",
    "        fmt=\"%d,%d,%d,%d,%d\",\n",
    "    )\n",
    "    return\n",
    "\n",
    "\n",
    "def appendAgents(agentsdb, pop, index, poly):\n",
    "    # Get a polygon\n",
    "    poly_pop = pop.TotalPop.to_list()[index]\n",
    "    ninarea = pointsWithinPolygon(poly)\n",
    "    if ninarea.shape[0] == 0:\n",
    "        return agentsdb\n",
    "    pop_per_node = int(poly_pop / ninarea.shape[0])\n",
    "    from_row = np.trim_zeros(agentsdb[:, 4], \"b\").shape[0]\n",
    "    to_row = from_row + ninarea.shape[0] * pop_per_node  # +1?\n",
    "    n = ninarea[\"# number\"].to_list()\n",
    "    nr = np.repeat(n, pop_per_node)\n",
    "    agentsdb[from_row:to_row, 4] = nr\n",
    "    return agentsdb\n",
    "\n",
    "def appendAgents2(agentsdb, pop, index, poly):\n",
    "    # Get a polygon\n",
    "    poly_pop = pop[\"pop\"].to_list()[index]\n",
    "    ninarea = pointsWithinPolygon(poly)\n",
    "    if ninarea.shape[0] == 0:\n",
    "        return agentsdb\n",
    "    pop_per_node = int(poly_pop / ninarea.shape[0])\n",
    "    from_row = np.trim_zeros(agentsdb[:, 4], \"b\").shape[0]\n",
    "    to_row = from_row + ninarea.shape[0] * pop_per_node  # +1?\n",
    "    n = ninarea[\"# number\"].to_list()\n",
    "    nr = np.repeat(n, pop_per_node)\n",
    "    agentsdb[from_row:to_row, 4] = nr\n",
    "    return agentsdb\n",
    "\n",
    "\n",
    "def copyDataFolder(case=\"kochi\"):\n",
    "    shutil.copytree(Path(\"./data\"), Path(f\"../{case}/data\"), dirs_exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Prefecture / Area of Interest / working CRS\n",
    "# case = 'kochi'\n",
    "# pref_code = 39\n",
    "# area = {'north': 33.58, 'south': 33.53, 'east': 133.58, 'west': 133.52}\n",
    "# crs = 'EPSG:6690'\n",
    "\n",
    "# Set Prefecture / Area of Interest / working CRS\n",
    "case = \"arahama\"\n",
    "pref_code = 4\n",
    "area = get_area_from_geojson(\"../input/arahama_aos.geojson\")\n",
    "crs = \"EPSG:6691\"\n",
    "before311 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create Folders\n",
    "createFolders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a Bounding Box of the area\n",
    "bbox = createBoundingBox(area=area)\n",
    "aos = gpd.GeoSeries([bbox]).to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Population in the Area of Study\n",
    "pop = gp.getPopulationArea(pref_code=pref_code, aos=aos, crs=crs, before311=before311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Graph object\n",
    "G = createGraph(area=area, crs=crs, ntype=\"drive\", simplify=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Shelter GeoDataframe\n",
    "shelters = getAreaShelters(area=area, pref_code=pref_code, crs=crs)\n",
    "if pref_code == 39:\n",
    "    bldgs = getAreaEvacBldgs(area=area, crs=crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create linksdb and nodesdb\n",
    "createLinksAndNodes(G, shelters, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create actionsdb and transitionsdb\n",
    "actrans.setMatrices()\n",
    "\n",
    "# Dissaggregate population\n",
    "df = pd.read_csv(\"./data/nodesdb.csv\")\n",
    "nodes = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.coord_x, df.coord_y),crs=6691)\n",
    "Gn = nodes\n",
    "gdf_int_wgs84 = pop\n",
    "Gn['pop']=[None]*Gn.shape[0]\n",
    "Gn_p = Gn.to_crs(crs=6691)\n",
    "gdf_int_wgs84.drop_duplicates(subset=['mesh','TotalPop'],inplace=True)\n",
    "Census_p = gdf_int_wgs84.to_crs(crs=6691)\n",
    "for i in range(gdf_int_wgs84.shape[0]-1):\n",
    "    pip = gpd.sjoin(Gn, gdf_int_wgs84.iloc[i:i+1,:], how=\"inner\", predicate='intersects')\n",
    "    if pip.empty:\n",
    "        pip = Census_p.iloc[i:i+1,:].sjoin_nearest(Gn_p, how=\"inner\")\n",
    "    n = pip.shape[0]\n",
    "    t = float(pip['TotalPop'].values[0])\n",
    "    a = np.round(t/n)\n",
    "    for idx, piprow in pip.iterrows():\n",
    "        if Gn.loc[idx,\"pop\"] is None:\n",
    "            Gn.loc[idx,\"pop\"]=a\n",
    "        else:\n",
    "            Gn.loc[idx,\"pop\"]=Gn.loc[idx,\"pop\"]+a\n",
    "#spread the difference among nodes with the smallest number of agents\n",
    "diff = np.ceil(sum([float(x) for x in Census_p['TotalPop']]))-Gn['pop'].sum()\n",
    "while diff > 5:\n",
    "    num_nodes = Gn[Gn[\"pop\"]==Gn[\"pop\"].min()].shape[0]\n",
    "    for idx, row in Gn[Gn[\"pop\"]==Gn[\"pop\"].min()].iterrows():\n",
    "        Gn.loc[idx,'pop']=Gn.loc[idx,'pop']+np.round(diff/num_nodes)\n",
    "    diff = np.ceil(sum([float(x) for x in Census_p['TotalPop']]))-Gn['pop'].sum()\n",
    "\n",
    "# Create the agentsdb\n",
    "num_people = Gn[\"pop\"].sum().astype(\"int64\")\n",
    "agentsdb = pd.DataFrame()\n",
    "agentsdb['age'] = [ 0 ] * num_people\n",
    "agentsdb['gender'] = [ 0 ] * num_people\n",
    "agentsdb['hhType'] = [ 0 ] * num_people\n",
    "agentsdb['hhId'] = [ 0 ] * num_people\n",
    "agentsdb['Node'] = [ -1 ] * num_people\n",
    "prev_sum = 0\n",
    "for i,r in Gn.iterrows():\n",
    "    if r['pop'] != None:\n",
    "        agg_pop = int(Gn['pop'].loc[:i].sum())\n",
    "        for j in range(prev_sum,prev_sum+int(r['pop'])):\n",
    "            agentsdb.iat[j,4] = int(r['# number'])\n",
    "        prev_sum = agg_pop\n",
    "    # else:\n",
    "    #     agentsdb['Node'].iloc[i] = None\n",
    "agentsdb = agentsdb.dropna()\n",
    "agentsdb['Node']=agentsdb['Node'].astype('int64')\n",
    "agentsdb.to_csv('./data/agentsdb.csv',index=False)\n",
    "\n",
    "copyDataFolder(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "pop.plot(column='TotalPop',ax=ax,legend=True)\n",
    "df = pd.read_csv(\"./data/nodesdb.csv\")\n",
    "nodes = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.coord_x, df.coord_y),crs=6691)\n",
    "nodes.plot(ax=ax)\n",
    "\n",
    "ctx.add_basemap(ax,zoom=18,\n",
    "                crs=pop.crs.to_string(),\n",
    "                source=ctx.providers.Esri.WorldImagery\n",
    "                )\n",
    "# gs = gpd.GeoSeries(nodes.geometry)\n",
    "# ninarea = nodes[gs.within(poly)]\n",
    "\n",
    "# for i in range(edDB.shape[0]):\n",
    "#         indS, indT= int(edDB[i,1]), int(edDB[i,2])\n",
    "#         # print(\"here\",indS, indT)\n",
    "#         plt.plot([ noDB[indS,1], noDB[indT,1] ],[ noDB[indS,2],noDB[indT,2] ], c=\"r\", lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gn = nodes\n",
    "gdf_int_wgs84 = pop\n",
    "Gn['pop']=[None]*Gn.shape[0]\n",
    "Gn_p = Gn.to_crs(crs=6691)\n",
    "gdf_int_wgs84.drop_duplicates(subset=['mesh','TotalPop'],inplace=True)\n",
    "Census_p = gdf_int_wgs84.to_crs(crs=6691)\n",
    "for i in range(gdf_int_wgs84.shape[0]-1):\n",
    "    pip = gpd.sjoin(Gn, gdf_int_wgs84.iloc[i:i+1,:], how=\"inner\", predicate='intersects')\n",
    "    if pip.empty:\n",
    "        pip = Census_p.iloc[i:i+1,:].sjoin_nearest(Gn_p, how=\"inner\")\n",
    "    n = pip.shape[0]\n",
    "    t = float(pip['TotalPop'].values[0])\n",
    "    a = np.round(t/n)\n",
    "    for idx, piprow in pip.iterrows():\n",
    "        if Gn.loc[idx,\"pop\"] is None:\n",
    "            Gn.loc[idx,\"pop\"]=a\n",
    "        else:\n",
    "            Gn.loc[idx,\"pop\"]=Gn.loc[idx,\"pop\"]+a\n",
    "#spread the difference among nodes with the smallest number of agents\n",
    "diff = np.ceil(sum([float(x) for x in Census_p['TotalPop']]))-Gn['pop'].sum()\n",
    "while diff > 5:\n",
    "    num_nodes = Gn[Gn[\"pop\"]==Gn[\"pop\"].min()].shape[0]\n",
    "    for idx, row in Gn[Gn[\"pop\"]==Gn[\"pop\"].min()].iterrows():\n",
    "        Gn.loc[idx,'pop']=Gn.loc[idx,'pop']+np.round(diff/num_nodes)\n",
    "    diff = np.ceil(sum([float(x) for x in Census_p['TotalPop']]))-Gn['pop'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "pop.plot(column='TotalPop',ax=ax,legend=True)\n",
    "df = pd.read_csv(\"./data/nodesdb.csv\")\n",
    "nodes = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.coord_x, df.coord_y),crs=6691)\n",
    "Gn.plot(column='pop', ax=ax, legend=True,cmap='jet',legend_kwds={'ncol':3})\n",
    "leg = ax.get_legend()\n",
    "leg.set_bbox_to_anchor((1.6, 0.8, 0.4, 0.2))\n",
    "ctx.add_basemap(ax,zoom=18,\n",
    "                crs=pop.crs.to_string(),\n",
    "                source=ctx.providers.Esri.WorldImagery\n",
    "                )\n",
    "# gs = gpd.GeoSeries(nodes.geometry)\n",
    "# ninarea = nodes[gs.within(poly)]\n",
    "\n",
    "# for i in range(edDB.shape[0]):\n",
    "#         indS, indT= int(edDB[i,1]), int(edDB[i,2])\n",
    "#         # print(\"here\",indS, indT)\n",
    "#         plt.plot([ noDB[indS,1], noDB[indT,1] ],[ noDB[indS,2],noDB[indT,2] ], c=\"r\", lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_people = Gn[\"pop\"].sum().astype(\"int64\")\n",
    "agentsdb = pd.DataFrame()\n",
    "agentsdb['age'] = [ 0 ] * num_people\n",
    "agentsdb['gender'] = [ 0 ] * num_people\n",
    "agentsdb['hhType'] = [ 0 ] * num_people\n",
    "agentsdb['hhId'] = [ 0 ] * num_people\n",
    "agentsdb['Node'] = [ -1 ] * num_people\n",
    "prev_sum = 0\n",
    "for i,r in Gn.iterrows():\n",
    "    if r['pop'] != None:\n",
    "        agg_pop = int(Gn['pop'].loc[:i].sum())\n",
    "        for j in range(prev_sum,prev_sum+int(r['pop'])):\n",
    "            agentsdb.iat[j,4] = int(r['# number'])\n",
    "        prev_sum = agg_pop\n",
    "    # else:\n",
    "    #     agentsdb['Node'].iloc[i] = None\n",
    "agentsdb = agentsdb.dropna()\n",
    "agentsdb['Node']=agentsdb['Node'].astype('int64')\n",
    "agentsdb.to_csv('./data/agentsdb.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tsuevac')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bda0322e35ecb825f0fb74b7e10c8909e10cf4f0acf6e958794327151495e59a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
